{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suitable-queens",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Basic-idea\" data-toc-modified-id=\"Basic-idea-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Basic idea</a></span></li><li><span><a href=\"#Requirements-and-Setup\" data-toc-modified-id=\"Requirements-and-Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Requirements and Setup</a></span></li><li><span><a href=\"#Input-(Please-Specify)\" data-toc-modified-id=\"Input-(Please-Specify)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Input (Please Specify)</a></span></li><li><span><a href=\"#Auto-Process\" data-toc-modified-id=\"Auto-Process-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Auto Process</a></span></li><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Data Preparation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Extract-Data-and-Normalization\" data-toc-modified-id=\"Extract-Data-and-Normalization-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Extract Data and Normalization</a></span></li><li><span><a href=\"#Compute-Distance-Matrix\" data-toc-modified-id=\"Compute-Distance-Matrix-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Compute Distance Matrix</a></span></li></ul></li><li><span><a href=\"#Choose-Parameter\" data-toc-modified-id=\"Choose-Parameter-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Choose Parameter</a></span><ul class=\"toc-item\"><li><span><a href=\"#Auto-picker\" data-toc-modified-id=\"Auto-picker-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Auto-picker</a></span></li><li><span><a href=\"#Parameter-scan\" data-toc-modified-id=\"Parameter-scan-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Parameter scan</a></span></li><li><span><a href=\"#Specify-parameters-manually\" data-toc-modified-id=\"Specify-parameters-manually-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Specify parameters manually</a></span></li></ul></li><li><span><a href=\"#Part-a)-Cluster-features-individual-using-CommonNN\" data-toc-modified-id=\"Part-a)-Cluster-features-individual-using-CommonNN-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Part a) Cluster features individual using CommonNN</a></span></li><li><span><a href=\"#One-hot-encoding\" data-toc-modified-id=\"One-hot-encoding-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>One-hot encoding</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#noice-and-no-interaction-are-the-same\" data-toc-modified-id=\"noice-and-no-interaction-are-the-same-8.0.1\"><span class=\"toc-item-num\">8.0.1&nbsp;&nbsp;</span>noice and no-interaction are the same</a></span></li><li><span><a href=\"#noice-and-no-interaction-are-different\" data-toc-modified-id=\"noice-and-no-interaction-are-different-8.0.2\"><span class=\"toc-item-num\">8.0.2&nbsp;&nbsp;</span>noice and no-interaction are different</a></span></li><li><span><a href=\"#One-hot-key-encoding\" data-toc-modified-id=\"One-hot-key-encoding-8.0.3\"><span class=\"toc-item-num\">8.0.3&nbsp;&nbsp;</span>One-hot key encoding</a></span></li></ul></li><li><span><a href=\"#Part-b)-Cluster-all-features-together\" data-toc-modified-id=\"Part-b)-Cluster-all-features-together-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Part b) Cluster all features together</a></span></li></ul></li><li><span><a href=\"#drop-noise\" data-toc-modified-id=\"drop-noise-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>drop noise</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-offer",
   "metadata": {},
   "source": [
    "## Basic idea\n",
    "\n",
    "Do a two-stage clustering:\n",
    "\n",
    "  - a) Cluster individual superfeatures to obtained states within each interaction\n",
    "  - b) Cluster all features together in a categorical state space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-puppy",
   "metadata": {},
   "source": [
    "## Requirements and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "plastic-texas",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:27:47.178046Z",
     "start_time": "2022-05-25T21:27:47.063630Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from parsers.ipynb\n",
      "importing Jupyter notebook from compute.ipynb\n",
      "importing Jupyter notebook from visualize.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuxinliu/miniconda3/envs/thesis2/lib/python3.10/site-packages/MDAnalysis/coordinates/chemfiles.py:108: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  MIN_CHEMFILES_VERSION = LooseVersion(\"0.9\")\n",
      "/home/yuxinliu/miniconda3/envs/thesis2/lib/python3.10/site-packages/MDAnalysis/coordinates/TRJ.py:1209: DeprecationWarning: Please use `netcdf_file` from the `scipy.io` namespace, the `scipy.io.netcdf` namespace is deprecated.\n",
      "  class NCDFPicklable(scipy.io.netcdf.netcdf_file):\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (<string>, line 190)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m~/miniconda3/envs/thesis2/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3361\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Input \u001b[1;32mIn [1]\u001b[0m in \u001b[1;35m<cell line: 19>\u001b[0m\n    import parsers, compute, visualize, clustering\n",
      "  File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m in \u001b[1;35m_find_and_load\u001b[0m\n",
      "  File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m in \u001b[1;35m_find_and_load_unlocked\u001b[0m\n",
      "  File \u001b[1;32m<frozen importlib._bootstrap>:672\u001b[0m in \u001b[1;35m_load_unlocked\u001b[0m\n",
      "  File \u001b[1;32m<frozen importlib._bootstrap>:632\u001b[0m in \u001b[1;35m_load_backward_compatible\u001b[0m\n",
      "  File \u001b[1;32m~/5_clustering/1_final/ipynb_importer.py:87\u001b[0m in \u001b[1;35mload_module\u001b[0m\n    exec(code, mod.__dict__)\n",
      "  File \u001b[1;32m<string>:12\u001b[0m in \u001b[1;35m<module>\u001b[0m\n",
      "  File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m in \u001b[1;35m_find_and_load\u001b[0m\n",
      "  File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m in \u001b[1;35m_find_and_load_unlocked\u001b[0m\n",
      "  File \u001b[1;32m<frozen importlib._bootstrap>:672\u001b[0m in \u001b[1;35m_load_unlocked\u001b[0m\n",
      "  File \u001b[1;32m<frozen importlib._bootstrap>:632\u001b[0m in \u001b[1;35m_load_backward_compatible\u001b[0m\n",
      "  File \u001b[1;32m~/5_clustering/1_final/ipynb_importer.py:87\u001b[0m in \u001b[1;35mload_module\u001b[0m\n    exec(code, mod.__dict__)\n",
      "  File \u001b[1;32m<string>:10\u001b[0m in \u001b[1;35m<module>\u001b[0m\n",
      "  File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m in \u001b[1;35m_find_and_load\u001b[0m\n",
      "  File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m in \u001b[1;35m_find_and_load_unlocked\u001b[0m\n",
      "  File \u001b[1;32m<frozen importlib._bootstrap>:672\u001b[0m in \u001b[1;35m_load_unlocked\u001b[0m\n",
      "  File \u001b[1;32m<frozen importlib._bootstrap>:632\u001b[0m in \u001b[1;35m_load_backward_compatible\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/5_clustering/1_final/ipynb_importer.py:87\u001b[0;36m in \u001b[0;35mload_module\u001b[0;36m\u001b[0m\n\u001b[0;31m    exec(code, mod.__dict__)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>:190\u001b[0;36m\u001b[0m\n\u001b[0;31m    if wrap_data = None:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "'''If any of the packages are not installed, you can intall with\n",
    "    !pip install package_name'''\n",
    "\n",
    "# from cnnclustering import cluster, hooks, plot\n",
    "import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# import mdtraj\n",
    "# import nglview\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import pairwise_distances\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn_extra import cluster as skecluster\n",
    "# from scipy.signal import argrelmax, argrelmin\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import ipynb_importer\n",
    "import parsers, compute, visualize, clustering\n",
    "\n",
    "import sys\n",
    "\n",
    "# sys.path\n",
    "# sys.path.append(f\"{os.getcwd()}/core\")\n",
    "# import parsers, compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-generic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:21:29.321493Z",
     "start_time": "2022-05-25T21:21:29.313586Z"
    }
   },
   "outputs": [],
   "source": [
    "# creat output folder\n",
    "output_directory = './output/'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# setup visualization params\n",
    "mpl.rcParams[\"figure.dpi\"] = 120\n",
    "annotation_options = {\n",
    "    \"annotate_pos\": \"random\",\n",
    "    \"annotate_props\": {\"fontweight\": \"bold\"}\n",
    "}\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4154c0",
   "metadata": {},
   "source": [
    "## Input (Please Specify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f4eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pml_path = '/home/yuxinliu/5_clustering/dynophore_out_2022-02-07_13-31-34-HIV/dyno_dynophore.pml'\n",
    "pdb_path = \"HIV.pdb\"\n",
    "dcd_path = \"HIV.dcd\"\n",
    "\n",
    "include_time = False\n",
    "n_drop = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b0118",
   "metadata": {},
   "source": [
    "## Auto Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71202c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, dynophore_dict = parsers.pre_process(pml_path, n_drop = n_drop, include_time = include_time)\n",
    "\n",
    "# or\n",
    "# dynophore3d_dict, _ = parsers.pml_to_dict(pml_path, n_drop = 500)\n",
    "\n",
    "# # overview number of frames per feature\n",
    "# {\n",
    "#     key: np.array([p[\"frame_ix\"] for p in value[\"points\"]]).shape[0]\n",
    "#     for key, value in dynophore3d_dict.items()\n",
    "# }\n",
    "\n",
    "# data = parsers.extract_norm(dynophore3d_dict)\n",
    "# data = compute.add_distance_mat(data, dynophore3d_dict, include_time=include_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f1770",
   "metadata": {},
   "outputs": [],
   "source": [
    "please_manual = clustering.auto_cluster(data, dynophore_dict, include_time = include_time, plot_search_parameter = True, plot_clustering = True)\n",
    "\n",
    "please_manual\n",
    "\n",
    "# or\n",
    "# data = compute.add_distance_mat(data, dynophore3d_dict, include_time=include_time)\n",
    "# data = compute.add_auto_param(data, dynophore3d_dict, include_time)\n",
    "# data, need_redo = clustering.do_cluster(data, include_time = include_time)\n",
    "# please_manual = clustering.params_adjust(data, need_redo, include_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b426da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = data['HBD[3220]']['clustering'].summary.to_DataFrame()\n",
    "checkpoint[checkpoint.radius_cutoff==0.100]\n",
    "\n",
    "# df[(df.n_clusters == 1)].sort_values([\"ratio_noise\", \"radius_cutoff\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-anniversary",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b127d98",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04df9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynophore3d_dict, _ = parsers.pml_to_dict(pml_path, n_drop = 500)\n",
    "\n",
    "# overview number of frames per feature\n",
    "{\n",
    "    key: np.array([p[\"frame_ix\"] for p in value[\"points\"]]).shape[0]\n",
    "    for key, value in dynophore3d_dict.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2208ad9d",
   "metadata": {},
   "source": [
    "### Extract Data and Normalization\n",
    "\n",
    "- xyz-coordinates and frame number are extracted\n",
    "- xyz-coordinates are normalized together to keep the relative proportion of the ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d6d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parsers.extract_norm(dynophore3d_dict)\n",
    "data['HBD[3142]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e5920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frame = max([x[\"frames\"][-1] for x in data.values()])\n",
    "max_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd308c9",
   "metadata": {},
   "source": [
    "### Compute Distance Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f01ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import pairwise_distances\n",
    "\n",
    "data = compute.add_distance_mat(data, dynophore3d_dict, include_time=include_time)\n",
    "\n",
    "print(data['HBD[3142]'][\"distances\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a987a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['HBD[3142]']['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f3f96",
   "metadata": {},
   "source": [
    "## Choose Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fdec3a",
   "metadata": {},
   "source": [
    "### Auto-picker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a095d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = compute.add_auto_param(data, dynophore3d_dict, include_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aaf348",
   "metadata": {},
   "source": [
    "### Parameter scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaa168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_status, new_params = parameter_scan(data, key=['HBD[3218]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488045fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rclustering = cluster.Clustering(data['HBD[3220]']['distances'])\n",
    "# # HBD[3218]\n",
    "# distance_rclustering = cluster.Clustering(data['HBD[3165]']['distances'], registered_recipe_key=\"distances\")\n",
    "# # r = 0.12\n",
    "# for r in tqdm(np.arange(0,1.5,0.2)):\n",
    "#     for c in range(10):\n",
    "#         # fit from pre-calculated distances\n",
    "#         distance_rclustering.fit(r, c, member_cutoff=10, v=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b50f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get summary sorted by number of identified clusters\n",
    "# # df = distance_rclustering.summary.to_DataFrame().sort_values('n_clusters')\n",
    "\n",
    "# df = distance_rclustering.summary.to_DataFrame()\n",
    "# df = df[(df.n_clusters == 1)].sort_values([\"ratio_noise\", \"radius_cutoff\"])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0804ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show cluster results where we have 3 clusters\n",
    "# df[(df.n_clusters == 1)].sort_values([\"ratio_noise\", \"radius_cutoff\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2ec7a6",
   "metadata": {},
   "source": [
    "### Specify parameters manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f921d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['NI[3217,3219,3218]'][\"params\"] = {\n",
    "    \"radius_cutoff\": 0.05,\n",
    "    \"cnn_cutoff\": 30,\n",
    "    \"member_cutoff\": 10    \n",
    "}\n",
    "\n",
    "data['NI[3201,3204,3202]'][\"params\"] = {\n",
    "    \"radius_cutoff\": 0.1,\n",
    "    \"cnn_cutoff\": 10,\n",
    "    \"member_cutoff\": 10\n",
    "}\n",
    "\n",
    "data['H[3131,3138,3133,3136,3135,3129]'][\"params\"] = {\n",
    "    \"radius_cutoff\": 0.04,\n",
    "    \"cnn_cutoff\": 13,\n",
    "    \"member_cutoff\": 5    \n",
    "}\n",
    "\n",
    "data['H[3187,3181,3178,3179,3185,3183]'][\"params\"] = {\n",
    "    \"radius_cutoff\": 0.05,\n",
    "    \"cnn_cutoff\": 10,\n",
    "    \"member_cutoff\": 5    \n",
    "}\n",
    "\n",
    "\n",
    "data['HBA[3218]'][\"params\"] = {\n",
    "    \"radius_cutoff\": 0.05,\n",
    "    \"cnn_cutoff\": 10,\n",
    "    \"member_cutoff\": 10    \n",
    "}\n",
    "\n",
    "data['HBD[3220]'][\"params\"] = {\n",
    "    \"radius_cutoff\": 0.05,\n",
    "    \"cnn_cutoff\": 10,\n",
    "    \"member_cutoff\": 5    \n",
    "}\n",
    "\n",
    "data['HBD[3165]'][\"params\"] = {\n",
    "    \"radius_cutoff\": 0.06,\n",
    "    \"cnn_cutoff\": 13,\n",
    "    \"member_cutoff\": 5    \n",
    "}\n",
    "\n",
    "\n",
    "data['HBD[3142]'][\"params\"] = {\n",
    "    \"radius_cutoff\": 0.06,\n",
    "    \"cnn_cutoff\": 3,\n",
    "    \"member_cutoff\": 5    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2046619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, need_redo = clustering.do_cluster(data, include_time = False, redo = None, plot = True, v = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b9edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "need_redo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-threshold",
   "metadata": {},
   "source": [
    "## Part a) Cluster features individual using CommonNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a936c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, need_redo = clustering.do_cluster(data, include_time = include_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b93fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "please_manual = clustering.params_adjust(data, need_redo, include_time)\n",
    "please_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59850d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster with adjusted parameter\n",
    "\n",
    "data, need_redo = clustering.do_cluster(data, include_time = include_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-sleeping",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T15:19:28.067300Z",
     "start_time": "2022-04-06T15:19:28.055637Z"
    }
   },
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a58a46",
   "metadata": {},
   "source": [
    "automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042d64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_extra import cluster as skecluster\n",
    "import numpy as np\n",
    "\n",
    "# def get_center_features(data, state_matrix, pam):\n",
    "#     '''Get prominent features for cluster centers\n",
    "#        input: dict\n",
    "#            data\n",
    "#         output: dict\n",
    "#             {binding_state_nr: {feature_name: {'state': state_within_feature, 'idx': superfaeture_idx}\n",
    "#             e.g.\n",
    "#             {0: {'H[3187,3181,3178,3179,3185,3183]': {'state': 0, 'idx': 0}}\n",
    "#     '''\n",
    "#     center_features = {}\n",
    "#     features = list(data.keys())\n",
    "#     for i in range(pam.cluster_centers_.shape[0]):\n",
    "#         print(i, \":\")\n",
    "#         features_tmp = {}\n",
    "#         present_feature_pos = np.where(pam.cluster_centers_[i] == 1)[0]\n",
    "#         states_per_interaction = clustering.get_states_per_interaction(state_matrix)\n",
    "\n",
    "#         for pos in present_feature_pos:\n",
    "#             feature_index, state = clustering.get_feature_state_from_onehot_position(pos, states_per_interaction)\n",
    "#             features_tmp[features[feature_index]] = {\"state\": state, \"idx\": feature_index}\n",
    "#             print(f\"    {features[feature_index]:>40} state {state:<10}\")\n",
    "        \n",
    "#         center_features[i] = features_tmp\n",
    "#     return center_features\n",
    "\n",
    "\n",
    "def binding_state_cluster(data, n_clusters = None):\n",
    "    if n_clusters == None:\n",
    "        state_matrix = compute.get_state_matrix(data)\n",
    "        one_hot_matrix = compute.get_one_hot_encoding(state_matrix)\n",
    "        clustering.get_binding_pose_cluster_inertia(one_hot_matrix)\n",
    "        n_clusters = int(input(\"Please give cluster number: \"))\n",
    "    else:\n",
    "        pass\n",
    "    pam = skecluster.KMedoids(n_clusters = n_clusters, metric = \"manhattan\", method = \"pam\")\n",
    "    pam.fit(one_hot_matrix)\n",
    "    pam.cluster_centers_\n",
    "    \n",
    "    get_center_features(data, state_matrix, pam)\n",
    "    return pam\n",
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "def split_trajectory(pam, pdb_path, dcd_path, n_drop = 0):\n",
    "    state_nr = np.max(pam.labels_)\n",
    "    cluster_frames_map = {\n",
    "        k: np.where(pam.labels_ == k)[0] + n_drop\n",
    "        for k in range(state_nr)\n",
    "    }\n",
    "    trajectory = mdtraj.load_dcd(\n",
    "            dcd_path,\n",
    "            top = pdb_path,\n",
    "            )\n",
    "\n",
    "    cluster_traj_map = {\n",
    "        k: trajectory[cluster_frames_map[k]]\n",
    "        for k in range(state_nr)\n",
    "    }\n",
    "    \n",
    "    cluster_traj_map[0]\n",
    "    \n",
    "    now_time = datetime.datetime.now().strftime('%Y_%m_%d_%H:%M')\n",
    "    output_directory = f\"./output/{now_time}/\"\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    for k, v in cluster_traj_map.items():\n",
    "        v.save_dcd(f\"{output_directory}cluster_{k}.dcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16011ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_trajectory(pam, pdb_path, dcd_path, n_drop = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddb0848",
   "metadata": {},
   "outputs": [],
   "source": [
    "pam = binding_state_cluster(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dc42e8",
   "metadata": {},
   "source": [
    "#### noice and no-interaction are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90653d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_matrix = compute.get_state_matrix(data)\n",
    "state_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a9724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc556a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# states (onehot elements) per interaction\n",
    "states_per_interaction = [max(x) + 1 for x in state_matrix.T]\n",
    "states_per_interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37d8043",
   "metadata": {},
   "source": [
    "#### noice and no-interaction are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-zimbabwe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:21:46.460477Z",
     "start_time": "2022-05-25T21:21:46.456483Z"
    }
   },
   "outputs": [],
   "source": [
    "# state_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-framework",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:21:46.698963Z",
     "start_time": "2022-05-25T21:21:46.694018Z"
    }
   },
   "outputs": [],
   "source": [
    "# state_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aad6958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # states (onehot elements) per interaction\n",
    "# states_per_interaction = [max(x) + 1 for x in state_matrix.T]\n",
    "# states_per_interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eea30d",
   "metadata": {},
   "source": [
    "#### One-hot key encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6730ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_matrix = compute.get_one_hot_encoding(state_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-partition",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:21:47.666002Z",
     "start_time": "2022-05-25T21:21:47.660621Z"
    }
   },
   "outputs": [],
   "source": [
    "one_hot_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-denial",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:21:48.022749Z",
     "start_time": "2022-05-25T21:21:48.015956Z"
    }
   },
   "outputs": [],
   "source": [
    "one_hot_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-stack",
   "metadata": {},
   "source": [
    "### Part b) Cluster all features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74b86da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_to_del = []\n",
    "\n",
    "# print(\"position in one_hot_matrix     (superfeature idx, state)\")\n",
    "# for pos in range(0, len(one_hot_matrix[0])):\n",
    "#     superfeature_idx, state = get_feature_state_from_onehot_position(pos, states_per_interaction)\n",
    "#     print_txt = \"\"\n",
    "#     if state == 0:\n",
    "#         col_to_del.append(pos)\n",
    "#         print_txt = \"(dropped)\"\n",
    "#     print(pos, (superfeature_idx, state), print_txt)\n",
    "\n",
    "# one_hot_matrix = np.delete(one_hot_matrix, col_to_del, axis=1)\n",
    "# print(len(one_hot_matrix[0]), \"states are considered (after dropping noises)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f828894",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering.get_binding_pose_cluster_inertia(one_hot_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-belly",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:23:04.649157Z",
     "start_time": "2022-05-25T21:23:01.888452Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4 or 5 clusters may be good\n",
    "from sklearn_extra import cluster as skecluster\n",
    "pam = skecluster.KMedoids(n_clusters=4, metric=\"manhattan\", method=\"pam\")\n",
    "pam.fit(one_hot_matrix)\n",
    "pam.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac28057",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_features = clustering.get_center_features(data, pam)\n",
    "center_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-convention",
   "metadata": {},
   "source": [
    "For more insight one may have to look at the dynophore structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-bradley",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:23:21.372878Z",
     "start_time": "2022-05-25T21:23:21.352433Z"
    }
   },
   "outputs": [],
   "source": [
    "pam.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-heading",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:28:15.269249Z",
     "start_time": "2022-05-25T21:28:15.256854Z"
    }
   },
   "outputs": [],
   "source": [
    "cluster_frames_map = {\n",
    "    k: np.where(pam.labels_ == k)[0]\n",
    "    for k in range(5)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-extraction",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:31:19.059032Z",
     "start_time": "2022-05-25T21:31:18.566070Z"
    }
   },
   "outputs": [],
   "source": [
    "import mdtraj\n",
    "trajectory = mdtraj.load_dcd(\n",
    "        \"HIV.dcd\",\n",
    "        top=\"HIV.pdb\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-authentication",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:31:54.737791Z",
     "start_time": "2022-05-25T21:31:53.635816Z"
    }
   },
   "outputs": [],
   "source": [
    "cluster_traj_map = {\n",
    "    k: trajectory[cluster_frames_map[k]]\n",
    "    for k in range(5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-reflection",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:32:48.575215Z",
     "start_time": "2022-05-25T21:32:48.559517Z"
    }
   },
   "outputs": [],
   "source": [
    "cluster_traj_map[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-prison",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:39:45.386658Z",
     "start_time": "2022-05-25T21:39:44.834269Z"
    }
   },
   "outputs": [],
   "source": [
    "for k, v in cluster_traj_map.items():\n",
    "#     print(k)\n",
    "    v.save_dcd(f\"output/hiv/cluster_3_0529_{k}.dcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-juvenile",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:33:41.171203Z",
     "start_time": "2022-05-25T21:33:41.011052Z"
    }
   },
   "outputs": [],
   "source": [
    "# view = nglview.show_mdtraj(cluster_traj_map[1])\n",
    "# view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-management",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:33:02.526449Z",
     "start_time": "2022-05-25T21:33:02.360256Z"
    }
   },
   "outputs": [],
   "source": [
    "# view = nglview.show_mdtraj(cluster_traj_map[0])\n",
    "# view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-position",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:34:16.293357Z",
     "start_time": "2022-05-25T21:34:16.129179Z"
    }
   },
   "outputs": [],
   "source": [
    "# view = nglview.show_mdtraj(cluster_traj_map[2])\n",
    "# view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-booking",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:34:39.187500Z",
     "start_time": "2022-05-25T21:34:39.034845Z"
    }
   },
   "outputs": [],
   "source": [
    "# view = nglview.show_mdtraj(cluster_traj_map[3])\n",
    "# view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f415bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynophore_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286ebcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb3910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''inspect which superfeatures appear in each states'''\n",
    "\n",
    "import dynophores as dyno\n",
    "import pandas as pd\n",
    "n_drop = 0\n",
    "\n",
    "dynophore = dyno.Dynophore.from_dir(\"../../5_clustering/dynophore_out_2022-02-06_16-44-28-ZIKA\")\n",
    "n_frames = dynophore.n_frames\n",
    "\n",
    "def extract_coor_frame(dynophore_dict, n_frames, n_drop):\n",
    "    df = pd.DataFrame(columns = dynophore_dict.keys(), index = range(n_frames - n_drop))\n",
    "    data_sp = []\n",
    "    for k, key in enumerate(dynophore_dict.keys()):\n",
    "        for i in dynophore_dict[key]['points']:\n",
    "            frame = int(list(i.values())[-2])\n",
    "#             print(frame)\n",
    "            \n",
    "            df.loc[frame, key] = 1\n",
    "            \n",
    "    return df\n",
    "\n",
    "df = extract_coor_frame(dynophore_dict, n_frames, n_drop = 500)\n",
    "\n",
    "\n",
    "interact_summary = np.empty(shape=(0, len(dynophore_dict.keys())))\n",
    "\n",
    "for label in np.unique(pam.labels_):\n",
    "    frames = pd.DataFrame(np.argwhere(pam.labels_ == label))[0].values.tolist()\n",
    "    count_frames = len(frames)\n",
    "#     print(count_frames)\n",
    "    summary = np.array(df.loc[frames].count()).astype(dtype=int)\n",
    "    summary = (summary/count_frames).round(2)\n",
    "    interact_summary = np.vstack((interact_summary, summary))\n",
    "\n",
    "interact_summary = pd.DataFrame(interact_summary.T)\n",
    "interact_summary.plot(figsize = (4,3))\n",
    "\n",
    "interact_summary[\"superfeature\"] = np.array(list(dynophore_dict.keys()))\n",
    "\n",
    "interact_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a565fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "n_frames = len(pam.labels_)\n",
    "x = range(n_frames)\n",
    "plt.figure(figsize=(15, 7), dpi=80)\n",
    "\n",
    "plt.scatter(x, pam.labels_, marker = \"|\")\n",
    "\n",
    "n_cluster = len(np.unique(pam.labels_))\n",
    "\n",
    "print(collections.Counter(pam.labels_))\n",
    "print(\"There are\", n_cluster, \"clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MDAnalysis as mda\n",
    "from MDAnalysis.analysis import align, rms, diffusionmap\n",
    "\n",
    "pdb_path = 'HIV.pdb'\n",
    "dcd_path = 'HIV.dcd'\n",
    "\n",
    "u = mda.Universe(pdb_path, dcd_path, in_memory=True)\n",
    "ligand = u.select_atoms('chainID X')\n",
    "\n",
    "reference_coordinates = u.trajectory.timeseries(asel=ligand).mean(axis=1)\n",
    "reference = mda.Merge(ligand).load_new(\n",
    "            reference_coordinates[:, None, :], order=\"afc\")\n",
    "ref_ca = reference.select_atoms('chainID X')\n",
    "\n",
    "aligner = align.AlignTraj(u, reference, select='chainID X', in_memory=True).run()\n",
    "\n",
    "rmsd_align_ls = []\n",
    "X_align =  range(len(u.trajectory))\n",
    "\n",
    "mobile = mda.Universe(pdb_path, dcd_path)\n",
    "\n",
    "for i in X_align:\n",
    "    \n",
    "    mobile.trajectory[i] # set mobile trajectory to last frame\n",
    "    mobile_ca = mobile.select_atoms('chainID X')\n",
    "\n",
    "    rmsd_ = rms.rmsd(mobile_ca.positions, ref_ca.positions, superposition=False)\n",
    "    rmsd_align_ls.append(rmsd_)\n",
    "    \n",
    "max_rmsd = np.max(np.array(rmsd_align_ls))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.plot(X_align, rmsd_align_ls)\n",
    "plt.ylim(bottom = 0)\n",
    "plt.title(f\"RMSD of ligand after alignment to mean coordinates: {round(np.mean(np.array(rmsd_align_ls)), 2)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7092d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "n_cluster = 4\n",
    "numRows =  math.ceil(n_cluster/3)\n",
    "numCols = 3\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "for k, i in enumerate(np.unique(pam.labels_)):\n",
    "#     row = i//3 + 1\n",
    "#     col = i%3 + 1\n",
    "    u = mda.Universe(pdb_path, f\"output/hiv/cluster_3_0529_{k}.dcd\", in_memory=True)\n",
    "    ligand = u.select_atoms('chainID X')\n",
    "    # reference = average structure\n",
    "    reference_coordinates = u.trajectory.timeseries(asel=ligand).mean(axis=1)\n",
    "    reference = mda.Merge(ligand).load_new(\n",
    "                reference_coordinates[:, None, :], order=\"afc\")\n",
    "    ref_ca = reference.select_atoms('chainID X')\n",
    "    aligner = align.AlignTraj(u, reference, select='chainID X', in_memory=True).run()\n",
    "    \n",
    "    \n",
    "    rmsd_align_ls = []\n",
    "    X_align =  range(len(u.trajectory))\n",
    "\n",
    "    mobile = mda.Universe(pdb_path, f\"output/hiv/cluster_3_0529_{k}.dcd\")\n",
    "\n",
    "    for j in X_align:\n",
    "        mobile.trajectory[j]\n",
    "        mobile_ca = mobile.select_atoms('chainID X')\n",
    "\n",
    "        rmsd_ = rms.rmsd(mobile_ca.positions, ref_ca.positions, superposition=False)\n",
    "        rmsd_align_ls.append(rmsd_)\n",
    "    \n",
    "    # plot\n",
    "    plt.subplot(numRows, numCols, (i + 1))\n",
    "    \n",
    "    plt.ylim(0, max_rmsd)\n",
    "    \n",
    "    plt.plot(X_align, rmsd_align_ls)\n",
    "    plt.title(f\"State {i} avg. RMSD = {round(np.mean(np.array(rmsd_align_ls)), 2)}\", fontsize = 8)\n",
    "    plt.xlabel(\"Frames\")\n",
    "    plt.ylabel(\"RMSD ($\\AA$)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f0dc76",
   "metadata": {},
   "source": [
    "## drop noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b27ec44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_to_del = []\n",
    "\n",
    "print(\"position in one_hot_matrix     (superfeature idx, state)\")\n",
    "for pos in range(0, len(one_hot_matrix[0])):\n",
    "    superfeature_idx, state = get_feature_state_from_onehot_position(pos, states_per_interaction)\n",
    "    print_txt = \"\"\n",
    "    if state == 0:\n",
    "        col_to_del.append(pos)\n",
    "        print_txt = \"(dropped)\"\n",
    "    print(pos, (superfeature_idx, state), print_txt)\n",
    "\n",
    "one_hot_matrix2 = np.delete(one_hot_matrix, col_to_del, axis=1)\n",
    "print(len(one_hot_matrix2[0]), \"states are considered (after dropping noises)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b7e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for n_clusters in tqdm(range(2, 8)):\n",
    "    pam = skecluster.KMedoids(n_clusters=n_clusters, metric=\"manhattan\", method=\"pam\")\n",
    "    pam.fit(one_hot_matrix)\n",
    "    inertia.append(pam.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4790f8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0aa6679",
   "metadata": {},
   "source": [
    "# backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b39289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import argrelmax, argrelmin\n",
    "\n",
    "# min_n_cluster = {}\n",
    "\n",
    "for i, key in enumerate(dynophore3d_dict.keys()):\n",
    "    if not include_time:\n",
    "        data_tmp = data[key][\"points\"]\n",
    "        distances = pairwise_distances(data_tmp)\n",
    "        radius_multi = 0.8\n",
    "    else:\n",
    "        distances = data[key][\"distances\"]\n",
    "        radius_multi = 0.8\n",
    "        \n",
    "    min_n_cluster = 0\n",
    "    min_freq = 0\n",
    "    frame_nr = len(distances[0])\n",
    "    \n",
    "    # plot\n",
    "    plt.figure(figsize=(3,2))\n",
    "    weights = np.zeros_like(distances.flatten()) + 1. / distances.flatten().size\n",
    "    plt.hist(distances.flatten(), bins=100, color='y', weights=weights)\n",
    "    print(\"===========================================================================\")\n",
    "    if frame_nr >= 300:  # TODO: depends on frequency  \n",
    "        # get the peaks and valleys' position\n",
    "        x_left = np.min(distances)\n",
    "        x_right = np.max(distances)\n",
    "        interval = (x_right - x_left)/20\n",
    "        \n",
    "        # predict min cluster number based on distance distribution\n",
    "        n_cluster = len(argrelmax(n)[0])\n",
    "        \n",
    "        \n",
    "        if n_cluster <= 4:\n",
    "            # get minimal frequency at valleys\n",
    "#             n, bins = np.histogram(distances, 20)\n",
    "            valley_pos = [i*5 for i in argrelmin(n)]\n",
    "            if len(y[valley_pos]):\n",
    "                min_freq = min(y[valley_pos])\n",
    "                print(\"min_freq:\", min_freq)\n",
    "\n",
    "            plt.ylabel(\"frequency\")\n",
    "            plt.title(f\"{i} {key}\")\n",
    "            plt.show()\n",
    "            print(\"==================\")\n",
    "            \n",
    "            \n",
    "            min_n_cluster = n_cluster\n",
    "            print(\"min cluster nr.:\", min_n_cluster)\n",
    "            \n",
    "            max_ = (np.array(argrelmax(n))*interval)[0]\n",
    "            min_ = (np.array(argrelmin(n))*interval)[0]\n",
    "            min_ = np.insert(min_, 0, 0)\n",
    "            print(\"max_:\", max_)\n",
    "            print(\"min_:\", min_)\n",
    "\n",
    "            # predict radius based on average peak width/2\n",
    "            min_len = min(len(max_), len(min_))\n",
    "            radius = np.mean(max_[:min_len] - min_[:min_len])*radius_multi\n",
    "            print(\"predict radius:\", radius)\n",
    "\n",
    "            # predict cnn_cutoff based on points number: 5%*points number\n",
    "            cnn_cutoff_ = min(frame_nr*(0.008+min_freq), 15)\n",
    "            print(\"predict cnn_cutoff:\", cnn_cutoff_)\n",
    "\n",
    "            data[key][\"params\"] = {\n",
    "                \"radius_cutoff\": radius,\n",
    "                \"cnn_cutoff\": cnn_cutoff_,\n",
    "                \"member_cutoff\": 10\n",
    "            }\n",
    "        data[key][\"min_cluster_n\"] = min_n_cluster\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c701a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import argrelmax, argrelmin\n",
    "\n",
    "# # min_n_cluster = {}\n",
    "\n",
    "# for i, key in enumerate(dynophore3d_dict.keys()):\n",
    "#     if not include_time:\n",
    "#         data_tmp = data[key][\"points\"]\n",
    "#         distances = pairwise_distances(data_tmp)\n",
    "#         radius_multi = 0.8\n",
    "#     else:\n",
    "#         distances = data[key][\"distances\"]\n",
    "#         radius_multi = 0.8\n",
    "        \n",
    "#     min_n_cluster = 0\n",
    "#     min_freq = 0\n",
    "#     frame_nr = len(distances[0])\n",
    "    \n",
    "#     # plot\n",
    "#     plt.figure(figsize=(3,2))\n",
    "#     weights = np.zeros_like(distances.flatten()) + 1. / distances.flatten().size\n",
    "#     plt.hist(distances.flatten(), bins=100, color='y', weights=weights)\n",
    "#     print(\"===========================================================================\")\n",
    "#     if frame_nr >= 300:  # TODO: depends on frequency  \n",
    "#         # get the peaks and valleys' position\n",
    "#         x_left = np.min(distances)\n",
    "#         x_right = np.max(distances)\n",
    "#         interval = (x_right - x_left)/20\n",
    "        \n",
    "#         # predict min cluster number based on distance distribution\n",
    "#         n_cluster = len(argrelmax(n)[0])\n",
    "        \n",
    "        \n",
    "#         if n_cluster <= 4:\n",
    "#             # get minimal frequency at valleys\n",
    "# #             n, bins = np.histogram(distances, 20)\n",
    "#             valley_pos = [i*5 for i in argrelmin(n)]\n",
    "#             if len(y[valley_pos]):\n",
    "#                 min_freq = min(y[valley_pos])\n",
    "#                 print(\"min_freq:\", min_freq)\n",
    "\n",
    "#             plt.ylabel(\"frequency\")\n",
    "#             plt.title(f\"{i} {key}\")\n",
    "#             plt.show()\n",
    "#             print(\"==================\")\n",
    "            \n",
    "            \n",
    "#             min_n_cluster = n_cluster\n",
    "#             print(\"min cluster nr.:\", min_n_cluster)\n",
    "            \n",
    "#             max_ = (np.array(argrelmax(n))*interval)[0]\n",
    "#             min_ = (np.array(argrelmin(n))*interval)[0]\n",
    "#             min_ = np.insert(min_, 0, 0)\n",
    "#             print(\"max_:\", max_)\n",
    "#             print(\"min_:\", min_)\n",
    "\n",
    "#             # predict radius based on average peak width/2\n",
    "#             min_len = min(len(max_), len(min_))\n",
    "#             radius = np.mean(max_[:min_len] - min_[:min_len])*radius_multi\n",
    "#             print(\"predict radius:\", radius)\n",
    "\n",
    "#             # predict cnn_cutoff based on points number: 5%*points number\n",
    "#             cnn_cutoff_ = min(frame_nr*(0.008+min_freq), 15)\n",
    "#             print(\"predict cnn_cutoff:\", cnn_cutoff_)\n",
    "\n",
    "#             data[key][\"params\"] = {\n",
    "#                 \"radius_cutoff\": radius,\n",
    "#                 \"cnn_cutoff\": cnn_cutoff_,\n",
    "#                 \"member_cutoff\": 10\n",
    "#             }\n",
    "#         data[key][\"min_cluster_n\"] = min_n_cluster\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f50088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distance histrogram\n",
    "\n",
    "# test = data['HBA[3210]'][\"points\"]\n",
    "# test = pairwise_distances(test)\n",
    "# test[0]\n",
    "\n",
    "# plt.plot([i for i in range(len(test[0]))], test[0])\n",
    "\n",
    "# n, bins = np.histogram(test[0], 20)\n",
    "# print(len(argrelmax(n)[0]))\n",
    "\n",
    "# plt.figure(figsize=(3,2))\n",
    "# plt.hist(test[0], bins=100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bd716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary = pd.DataFrame()\n",
    "\n",
    "# # for i, key in enumerate(data.keys()):\n",
    "# #     data_\n",
    "    \n",
    "    \n",
    "# for i, key in enumerate(data.keys()):\n",
    "#     summary_ = data[key][\"clustering\"].summary.to_DataFrame()\n",
    "#     summary = pd.concat((summary, summary_), ignore_index=True)\n",
    "    \n",
    "# summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af6b056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with time\n",
    "\n",
    "data['H[3131,3138,3133,3136,3135,3129]'][\"params\"] = {\n",
    "    \"radius_cutoff\": 0.05,\n",
    "    \"cnn_cutoff\": 30,\n",
    "    \"member_cutoff\": 5    \n",
    "}\n",
    "\n",
    "data['NI[3217,3219,3218]'][\"params\"] = {\n",
    "    \"radius_cutoff\": 0.05,\n",
    "    \"cnn_cutoff\": 50,\n",
    "    \"member_cutoff\": 5    \n",
    "}\n",
    "\n",
    "data['HBA[3219]'][\"params\"] = {\n",
    "    \"radius_cutoff\": 0.05,\n",
    "    \"cnn_cutoff\": 15,\n",
    "    \"member_cutoff\": 5    \n",
    "}\n",
    "\n",
    "data['HBA[3218]'][\"params\"] = {\n",
    "    \"radius_cutoff\": 0.05,\n",
    "    \"cnn_cutoff\": 15,\n",
    "    \"member_cutoff\": 5    \n",
    "}\n",
    "\n",
    "data['HBD[3165]'][\"params\"] = {\n",
    "    \"radius_cutoff\": 0.05,\n",
    "    \"cnn_cutoff\": 5,\n",
    "    \"member_cutoff\": 5    \n",
    "}\n",
    "\n",
    "# looks not so good\n",
    "data['HBD[3169]'][\"params\"] = {\n",
    "    \"radius_cutoff\": 0.05,\n",
    "    \"cnn_cutoff\": 3,\n",
    "    \"member_cutoff\": 5    \n",
    "}\n",
    "\n",
    "data['HBD[3142]'][\"params\"] = {\n",
    "    \"radius_cutoff\": 0.05,\n",
    "    \"cnn_cutoff\": 0,\n",
    "    \"member_cutoff\": 5    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002e1e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: a log to record process\n",
    "\n",
    "repeat = 10\n",
    "please_manual = []\n",
    "need_redo_copy = need_redo.copy()\n",
    "\n",
    "for key, info in need_redo_copy.items():\n",
    "    print(\"*\"*100)\n",
    "    print(f\"Start working on {key}\")\n",
    "    \n",
    "    fix_status = False\n",
    "    reasons = info[\"reasons\"]\n",
    "    \n",
    "    radius_cutoff, cnn_cutoff, member_cutoff = data[key][\"params\"].values()\n",
    "\n",
    "    # only the noise problem\n",
    "    if reasons == [\"noise\"]:\n",
    "        time = 0\n",
    "        while time < repeat and cnn_cutoff >= 0 and fix_status == False:  # if number of clusters wrong or noise is decreased, no need to continue running\n",
    "            print(\"naive methods\")\n",
    "            time += 1\n",
    "            cnn_cutoff -= 1\n",
    "            data[key][\"params\"]['cnn_cutoff'] = cnn_cutoff\n",
    "            data_temp, need_redo_temp = auto_cluster(data, include_time = include_time, redo = [key])\n",
    "            if key not in need_redo_temp.keys():\n",
    "                fix_status = True\n",
    "        if not fix_status:\n",
    "            fix_status = parameter_scan(data, key)\n",
    "            \n",
    "    # if involve the problem of unsatisfied cluster number\n",
    "    else:\n",
    "        fix_status = parameter_scan(data, key)\n",
    "        \n",
    "    if fix_status:\n",
    "#         need_redo = need_redo.pop(key) \n",
    "        del need_redo[key]\n",
    "        print(f\"Solution found for {key}\")\n",
    "    else:\n",
    "        please_manual.append(key)\n",
    "        print(f\"Failed for {key}\")\n",
    "    \n",
    "please_manual"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.302px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
