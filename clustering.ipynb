{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb2cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from cnnclustering import cluster\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn_extra import cluster as skecluster\n",
    "import ipynb_importer\n",
    "import visualize, compute\n",
    "\n",
    "def do_cluster(data, include_time = False, redo = None, plot = True, v = True):\n",
    "    '''cluster data within each superfeature sequently\n",
    "       output: dict, list\n",
    "               data with fitted cluster, superfeatures needed redo'''\n",
    "    # setup visualization params\n",
    "    mpl.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "    fig, Ax = plt.subplots(len(data), 4,\n",
    "                           figsize=(mpl.rcParams[\"figure.figsize\"][0] * 3, mpl.rcParams[\"figure.figsize\"][1] * len(data) * 1.2))\n",
    "    default_cluster_params = {\n",
    "        \"radius_cutoff\": 0.2,\n",
    "        \"cnn_cutoff\": 5,\n",
    "        \"member_cutoff\": 10\n",
    "    }\n",
    "    need_redo = {}\n",
    "    \n",
    "    if not redo:\n",
    "        redo = data.keys()\n",
    "        \n",
    "    for i, (fkey, data_) in enumerate(data.items()):\n",
    "        if \"clustering\" not in data[fkey]:\n",
    "            if include_time:\n",
    "                data[fkey][\"clustering\"] = cluster.Clustering(data_[\"distances\"], registered_recipe_key=\"distances\")\n",
    "            else:\n",
    "                data[fkey][\"clustering\"] = cluster.Clustering(data_[\"points\"])\n",
    "        if not include_time:\n",
    "            for axi, d in enumerate([0, 1]):\n",
    "                data[fkey][\"clustering\"].evaluate(\n",
    "                    ax=Ax[i, axi], dim=(d, d+1),\n",
    "                    original=True\n",
    "                )\n",
    "        if fkey in redo:\n",
    "            print(i, fkey)\n",
    "            data[fkey][\"clustering\"].fit(**data_.get(\"params\", default_cluster_params), v=v)\n",
    "        \n",
    "        # plot\n",
    "            if include_time and plot:\n",
    "                visualize.visualize_clustering(data_, i, fkey)\n",
    "            n_cluster_real = list(data[fkey][\"clustering\"].summary.to_DataFrame()[\"n_clusters\"])[-1]\n",
    "            ratio_noise = list(data[fkey][\"clustering\"].summary.to_DataFrame()[\"ratio_noise\"])[-1]\n",
    "                \n",
    "            reasons = []\n",
    "            if n_cluster_real < data[fkey]['min_cluster_n']:\n",
    "                print(f\"Fewer clusters than expected! Now: {n_cluster_real}  Expected: {data[fkey]['min_cluster_n']}\")\n",
    "                reasons.append(\"n_clusters\")\n",
    "            if ratio_noise > 0.05 and ratio_noise < 1:\n",
    "                print(\"Noise over 5%!\")\n",
    "                reasons.append(\"noise\")\n",
    "            if len(reasons):\n",
    "                need_redo[fkey] = {\"reasons\": reasons, \"idx\": i}\n",
    "        \n",
    "        if not include_time:\n",
    "            for axi, d in enumerate([0, 1], 2):\n",
    "                data[fkey][\"clustering\"].evaluate(\n",
    "                    ax=Ax[i, axi], dim=(d, d+1),\n",
    "                )\n",
    "            Ax[i, 0].annotate(f\"{i}: {fkey}\", (0.05, 0.95), xycoords=\"axes fraction\", fontsize=10)\n",
    "            \n",
    "    if need_redo:\n",
    "        print(\"Following feature will be reclustered\")\n",
    "        \n",
    "        # formating info table\n",
    "        print(\"{:<4} {:<35} {:<15}\".format('idx', 'key', 'reason'))\n",
    "        max_len_key = 0\n",
    "        for key_ in need_redo.keys():\n",
    "            max_len_key = max(max_len_key, len(key_))\n",
    "        \n",
    "        for key_, value_ in need_redo.items():\n",
    "            idx, reason = value_[\"idx\"], value_[\"reasons\"]\n",
    "            print(\"{:<4} {:<35} {:<15}\".format(idx, key_, str(reason)))\n",
    "    else:\n",
    "        print(\"From computer's view, no cluster need manual parameter adjustment\")\n",
    "            \n",
    "    return data, need_redo\n",
    "\n",
    "# def do_cluster(data, include_time = False, redo = None, plot = True, v = True):\n",
    "#     '''cluster data within each superfeature sequently\n",
    "#        output: dict, list\n",
    "#                data with fitted cluster, superfeatures needed redo'''\n",
    "    \n",
    "#     default_cluster_params = {\n",
    "#         \"radius_cutoff\": 0.2,\n",
    "#         \"cnn_cutoff\": 5,\n",
    "#         \"member_cutoff\": 10\n",
    "#     }\n",
    "#     need_redo = {}\n",
    "    \n",
    "#     if not redo:\n",
    "#         redo = data.keys()\n",
    "        \n",
    "#     for i, (fkey, data_) in enumerate(data.items()):\n",
    "#         if \"clustering\" not in data[fkey]:\n",
    "#             if include_time:\n",
    "#                 data[fkey][\"clustering\"] = cluster.Clustering(data_[\"distances\"], registered_recipe_key=\"distances\")\n",
    "#             else:\n",
    "#                 data[fkey][\"clustering\"] = cluster.Clustering(data_[\"points\"])\n",
    "        \n",
    "#         if fkey in redo:\n",
    "#             print(i, fkey)\n",
    "#             data[fkey][\"clustering\"].fit(**data_.get(\"params\", default_cluster_params), v=v)\n",
    "        \n",
    "#         # plot\n",
    "#             if plot:\n",
    "#                 visualize.visualize_clustering(data_, i, fkey)\n",
    "#             n_cluster_real = list(data[fkey][\"clustering\"].summary.to_DataFrame()[\"n_clusters\"])[-1]\n",
    "#             ratio_noise = list(data[fkey][\"clustering\"].summary.to_DataFrame()[\"ratio_noise\"])[-1]\n",
    "        \n",
    "#             reasons = []\n",
    "#             if n_cluster_real < data[fkey]['min_cluster_n']:\n",
    "#                 print(f\"Fewer clusters than expected! Now: {n_cluster_real}  Expected: {data[fkey]['min_cluster_n']}\")\n",
    "#                 reasons.append(\"n_clusters\")\n",
    "#             if ratio_noise > 0.05 and ratio_noise < 1:\n",
    "#                 print(\"Noise over 5%!\")\n",
    "#                 reasons.append(\"noise\")\n",
    "#             if len(reasons):\n",
    "#                 need_redo[fkey] = {\"reasons\": reasons, \"idx\": i}\n",
    "        \n",
    "#     return data, need_redo\n",
    "\n",
    "\n",
    "def parameter_scan(data, key, r_start = 0.05, r_end = 0.3, r_step = 0.05, c_statr = 0, c_end = 50, c_step = 2, include_time = False):\n",
    "    '''parameter scan for data of specific superfeature\n",
    "       output: tuple\n",
    "           new parameters if found\n",
    "           else old parameters\n",
    "           \n",
    "        during the process, parameters in input data are changed if solution found\n",
    "    '''\n",
    "    try:\n",
    "        cluster_ = data[key][\"clustering\"]\n",
    "    except:\n",
    "        if include_time:\n",
    "            data[key][\"clustering\"] = cluster.Clustering(data[key][\"distances\"], registered_recipe_key=\"distances\")\n",
    "        else:\n",
    "            data[key][\"clustering\"] = cluster.Clustering(data[key][\"points\"])\n",
    "    min_cluster_n = data[key][\"min_cluster_n\"]\n",
    "    orig_radius_cutoff, orig_cnn_cutoff, orig_member_cutoff = data[key][\"params\"][\"radius_cutoff\"], data[key][\"params\"][\"cnn_cutoff\"], data[key][\"params\"][\"member_cutoff\"]\n",
    "    for r in tqdm(np.arange(r_start, r_end, r_step)):\n",
    "        for c in np.arange(c_statr, c_end, c_step):\n",
    "            # fit from pre-calculated distances\n",
    "            cluster_.fit(r, c, member_cutoff=10, v=False)\n",
    "    \n",
    "    # Get summary sorted by number of identified clusters\n",
    "    df = cluster_.summary.to_DataFrame()\n",
    "    df = df[(df.n_clusters == min_cluster_n)][(df.ratio_noise > 0)].sort_values([\"ratio_noise\", \"radius_cutoff\"])\n",
    "    radius_cutoff, cnn_cutoff, ratio_noise = df.iloc[0][[\"radius_cutoff\", \"cnn_cutoff\", \"ratio_noise\"]]\n",
    "    \n",
    "    # save the corrected parameters and cluster object\n",
    "    if ratio_noise < 0.05:\n",
    "        data[key][\"params\"][\"radius_cutoff\"], data[key][\"params\"][\"radius_cutoff\"] = radius_cutoff, cnn_cutoff\n",
    "        cluster_.fit(radius_cutoff, cnn_cutoff, member_cutoff=10, v=True)\n",
    "        print(\"Solution found with parameter scan\")\n",
    "        return (radius_cutoff, cnn_cutoff, orig_member_cutoff)\n",
    "    else:\n",
    "        print(f\"Cannot find solution for {key}\")\n",
    "        return (orig_radius_cutoff, orig_cnn_cutoff, orig_member_cutoff)\n",
    "    \n",
    "\n",
    "def params_adjust(data, need_redo, include_time = False, repeat = 10, plot = True, v = True):\n",
    "    '''Adjust parameter for features in need_redo\n",
    "       output: list\n",
    "           a list of feature names which need manual parameters'''\n",
    "    please_manual = []\n",
    "    need_redo_copy = need_redo.copy()\n",
    "\n",
    "    for key, info in need_redo_copy.items():\n",
    "        print(\"*\"*100)\n",
    "        print(f\"Start working on {key}\")\n",
    "\n",
    "        fix_status = False\n",
    "        reasons = info[\"reasons\"]\n",
    "        radius_cutoff, cnn_cutoff, member_cutoff = data[key][\"params\"].values()\n",
    "\n",
    "        # only the noise problem\n",
    "        if reasons == [\"noise\"]:\n",
    "            time = 0\n",
    "            print(\"Start adjusting parameters\")\n",
    "            while time < repeat and cnn_cutoff >= 2 and fix_status == False:  # if number of clusters wrong or noise is decreased, no need to continue running\n",
    "                time += 1\n",
    "                cnn_cutoff -= 2\n",
    "                data[key][\"params\"]['cnn_cutoff'] = cnn_cutoff\n",
    "                data_temp, need_redo_temp = do_cluster(data, include_time = include_time, plot = plot, redo = [key], v = v)\n",
    "                if key not in need_redo_temp.keys():\n",
    "                    fix_status = True\n",
    "                    new_radius_cutoff, new_cnn_cutoff = (radius_cutoff, cnn_cutoff)\n",
    "            if not fix_status:\n",
    "                print(\"Parameter adjustment failed. Start parameter scan\")\n",
    "                (new_radius_cutoff, new_cnn_cutoff, new_member_cutoff) = parameter_scan(data, key)\n",
    "\n",
    "        # if involve the problem of unsatisfied cluster number\n",
    "        else:\n",
    "            (new_radius_cutoff, new_cnn_cutoff, new_member_cutoff) = parameter_scan(data, key)\n",
    "            if (new_radius_cutoff, new_cnn_cutoff, new_member_cutoff) != (radius_cutoff, cnn_cutoff, member_cutoff):\n",
    "                fix_status = True\n",
    "            \n",
    "        if fix_status:\n",
    "            del need_redo[key]\n",
    "            data[key][\"params\"][\"radius_cutoff\"], data[key][\"params\"][\"cnn_cutoff\"] = new_radius_cutoff, new_cnn_cutoff\n",
    "            print(f\"Solution found for {key}\")\n",
    "        else:\n",
    "            please_manual.append(key)\n",
    "            print(f\"Failed for {key}\")\n",
    "    return please_manual, data\n",
    "\n",
    "\n",
    "def auto_cluster(data, dynophore3d_dict, include_time = False, only_result = True, info_table = True, \n",
    "                 frequency_cutoff = 0.06, redo = None, plot_search_parameter = True, \n",
    "                 plot_clustering = True, plot_params_adjust = False, repeat = 10, v = True):\n",
    "    if only_result:\n",
    "        info_table = False\n",
    "        plot_search_parameter = False\n",
    "        plot_clustering = False\n",
    "        plot_params_adjust = False\n",
    "        v = False\n",
    "    \n",
    "    data = compute.add_auto_param(data, dynophore3d_dict, include_time = include_time, \n",
    "                                  info_table = info_table, frequency_cutoff = frequency_cutoff, plot = plot_search_parameter)\n",
    "    \n",
    "    data, need_redo = do_cluster(data, include_time = include_time, redo = redo, plot = plot_clustering, v = v)\n",
    "    print(\"1. Clustering attemp finished\")\n",
    "    if need_redo:\n",
    "        please_manual, data = params_adjust(data, need_redo = need_redo, include_time = include_time, \n",
    "                                            repeat = repeat, plot = plot_params_adjust, v=v)\n",
    "\n",
    "    # use adjusted parameter to do the clustering -> show result\n",
    "    print(\"Result\")\n",
    "    data, need_redo = do_cluster(data, include_time = False, redo = None, plot = True, v = True)\n",
    "    \n",
    "    if please_manual:\n",
    "        print(\"Please sepecify parameters for following features. No parameter found automatically.\")\n",
    "        print(please_manual)\n",
    "    else:\n",
    "        print(\"Clustering finished! You may adjust parameters for better result manually.\")\n",
    "        \n",
    "    return please_manual\n",
    "\n",
    "\n",
    "def get_binding_pose_cluster_inertia(one_hot_matrix, min_cluster = 2, max_cluster = 7):\n",
    "    '''Scan cluster number for input one_hot_matrix\n",
    "       plot inertia, i.e. the difference within each cluster given cluster number\n",
    "       input: ndarray\n",
    "           frame | existance of state 0 in superfeature 1 | existance of state 1 in superfeature 1...\n",
    "           1     | 1 (means exist)                        | 0 (means absence)\n",
    "           2     ...\n",
    "           3     ...\n",
    "        '''\n",
    "    inertia = []\n",
    "    for n_clusters in tqdm(range(min_cluster, max_cluster)):\n",
    "        pam = skecluster.KMedoids(n_clusters = n_clusters, metric = \"manhattan\", method = \"pam\")\n",
    "        pam.fit(one_hot_matrix)\n",
    "        inertia.append(pam.inertia_)\n",
    "    # plot  \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(range(min_cluster, max_cluster), inertia)\n",
    "    ax.set_xlabel(\"#clusters\")\n",
    "    ax.set_ylabel(\"inertia: difference within each cluster\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def get_feature_state_from_onehot_position(pos, states_per_interaction):\n",
    "    '''Retrace which features and state is represented by a onehot matrix position'''\n",
    "    cumsum = 0\n",
    "    newcumsum = 0\n",
    "    for i, state_count in enumerate(states_per_interaction):\n",
    "        newcumsum += state_count\n",
    "        if pos < newcumsum:\n",
    "            return (i, pos - cumsum)\n",
    "        cumsum = newcumsum\n",
    "    return (i, pos)\n",
    "\n",
    "\n",
    "def get_states_per_interaction(state_matrix):\n",
    "    return [max(x) + 1 for x in state_matrix.T]\n",
    "\n",
    "\n",
    "def get_center_features(data, state_matrix, pam):\n",
    "    '''Get prominent features for cluster centers\n",
    "       input: dict\n",
    "           data\n",
    "        output: dict\n",
    "            {binding_state_nr: {feature_name: {'state': state_within_feature, 'idx': superfaeture_idx}\n",
    "            e.g.\n",
    "            {0: {'H[3187,3181,3178,3179,3185,3183]': {'state': 0, 'idx': 0}}\n",
    "    '''\n",
    "    center_features = {}\n",
    "    features = list(data.keys())\n",
    "    for i in range(pam.cluster_centers_.shape[0]):\n",
    "        print(i, \":\")\n",
    "        features_tmp = {}\n",
    "        present_feature_pos = np.where(pam.cluster_centers_[i] == 1)[0]\n",
    "        states_per_interaction = get_states_per_interaction(state_matrix)\n",
    "\n",
    "        for pos in present_feature_pos:\n",
    "            feature_index, state = get_feature_state_from_onehot_position(pos, states_per_interaction)\n",
    "            features_tmp[features[feature_index]] = {\"state\": state, \"idx\": feature_index}\n",
    "            print(f\"    {features[feature_index]:>40} state {state:<10}\")\n",
    "        \n",
    "        center_features[i] = features_tmp\n",
    "    return center_features\n",
    "\n",
    "\n",
    "def binding_state_cluster(data, n_clusters = None):\n",
    "    '''Interactive funtion to do one hot key clustering for recognizing binding poses\n",
    "       input: dict, int\n",
    "       output: KMedoids object'''\n",
    "    state_matrix = compute.get_state_matrix(data)\n",
    "    one_hot_matrix = compute.get_one_hot_encoding(state_matrix)\n",
    "    if n_clusters == None:\n",
    "        get_binding_pose_cluster_inertia(one_hot_matrix)\n",
    "        n_clusters = int(input(\"Please give cluster number: \"))\n",
    "    pam = skecluster.KMedoids(n_clusters = n_clusters, metric = \"manhattan\", method = \"pam\")\n",
    "    pam.fit(one_hot_matrix)\n",
    "    pam.cluster_centers_\n",
    "    \n",
    "    get_center_features(data, state_matrix, pam)\n",
    "    return pam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
