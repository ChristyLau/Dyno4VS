{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb78a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Contains parsers for\n",
    "- Dynophore JSON file, which contains statistis on the occurrences and distances of superfeatures\n",
    "  and environmental partners\n",
    "- Dynophore PML file, which contains 3D coordinates for points in superfeature\n",
    "  point clouds\n",
    "\"\"\"\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import ipynb_importer\n",
    "import compute\n",
    "import dynophores as dyno\n",
    "from matplotlib import colors\n",
    "import ipynb_importer\n",
    "import write\n",
    "\n",
    "\n",
    "def extract_coordinates(dyno_dict, feature_key):\n",
    "    \"\"\"Extract xyz-trajectory for one feature into a 2D NumPy array\"\"\"\n",
    "    coordinates = []\n",
    "    last_frame = None\n",
    "    for p in dyno_dict[feature_key]['points']:\n",
    "        if p[\"frame_ix\"] == last_frame:\n",
    "            continue\n",
    "        last_frame = p[\"frame_ix\"]\n",
    "        coordinates.append([p[\"x\"], p[\"y\"], p[\"z\"]])\n",
    "    return np.asarray(coordinates)\n",
    "\n",
    "\n",
    "def extract_time(dyno_dict, feature_key):\n",
    "    \"\"\"Extract frame id for one feature into a 1D NumPy array\"\"\"\n",
    "    time = []\n",
    "    last_frame = None\n",
    "    for p in dyno_dict[feature_key]['points']:\n",
    "        if p[\"frame_ix\"] == last_frame:\n",
    "            continue\n",
    "        last_frame = p[\"frame_ix\"]\n",
    "        time.append(p[\"frame_ix\"])\n",
    "    return np.asarray(time)\n",
    "\n",
    "\n",
    "def extract_norm(dyno_dict):\n",
    "    '''Normalize xyz coordinates and add frame information'''\n",
    "    data = {}\n",
    "    for key in dyno_dict.keys():\n",
    "        points_tmp = extract_coordinates(dyno_dict, key)\n",
    "        if points_tmp != []:\n",
    "            points_min, points_max = np.min(points_tmp), np.max(points_tmp)\n",
    "            norm_points = (points_tmp-points_min)/(points_max-points_min)\n",
    "            frames = extract_time(dyno_dict, key)\n",
    "            data[key] = {\n",
    "                \"points\": norm_points,\n",
    "                \"frames\": frames,\n",
    "                \"non_norm\": points_tmp\n",
    "            }\n",
    "        else:\n",
    "            frames = extract_time(dyno_dict, key)\n",
    "            data[key] = {\n",
    "                \"points\": np.array([0, 0, 0]).reshape(-1, 1),\n",
    "                \"frames\": frames,\n",
    "                \"non_norm\": np.array([0, 0, 0]).reshape(-1, 1)\n",
    "            }\n",
    "    return data\n",
    "\n",
    "\n",
    "def pml_to_dict(pml_path, n_drop = 0):\n",
    "    \"\"\"\n",
    "    Parse PML file content (selections of it).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pml_path : str or pathlib.Path\n",
    "        Path to PML file.\n",
    "    n_drop : int\n",
    "        number of frames to drop counting from frame 0\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Superfeature data with the following keys and nested keys (key : value data type):\n",
    "\n",
    "        Example:\n",
    "        - <superfeature id>\n",
    "          - id : str\n",
    "          - color : str\n",
    "          - center : numpy.array\n",
    "          - points : list\n",
    "            - x : float\n",
    "            - y : float\n",
    "            - z : float\n",
    "            - frame_ix : int\n",
    "            - weight : float\n",
    "    \"\"\"\n",
    "\n",
    "    dynophore3d_xml = ET.parse(pml_path)\n",
    "    dynophore3d_dict = {}\n",
    "\n",
    "    feature_clouds = dynophore3d_xml.findall(\"featureCloud\")\n",
    "    for feature_cloud in feature_clouds:\n",
    "\n",
    "        # Superfeature ID\n",
    "        superfeature_feature_name = feature_cloud.get(\"name\")\n",
    "        superfeature_atom_numbers = feature_cloud.get(\"involvedAtomSerials\")\n",
    "        superfeature_id = f\"{superfeature_feature_name}[{superfeature_atom_numbers}]\"\n",
    "        # Superfeature color\n",
    "        superfeature_color = feature_cloud.get(\"featureColor\")\n",
    "        # Superfeature cloud center\n",
    "        center = feature_cloud.find(\"position\")\n",
    "        center_data = np.array(\n",
    "            [\n",
    "                float(center.get(\"x3\")),\n",
    "                float(center.get(\"y3\")),\n",
    "                float(center.get(\"z3\")),\n",
    "            ]\n",
    "        )\n",
    "        # Superfeature cloud points\n",
    "        additional_points = feature_cloud.findall(\"additionalPoint\")\n",
    "        additional_points_data = []\n",
    "        for additional_point in additional_points:\n",
    "            frame_ix = int(additional_point.get(\"frameIndex\"))\n",
    "            #################\n",
    "#             print(\"original:\", frame_ix)\n",
    "\n",
    "            if frame_ix >= n_drop:\n",
    "#                 print(\"after:\", frame_ix - n_drop)\n",
    "                additional_point_data = {\n",
    "                    \"x\": float(additional_point.get(\"x3\")),\n",
    "                    \"y\": float(additional_point.get(\"y3\")),\n",
    "                    \"z\": float(additional_point.get(\"z3\")),\n",
    "                    \"frame_ix\": frame_ix - n_drop,\n",
    "                    \"weight\": float(additional_point.get(\"weight\")),\n",
    "                }\n",
    "                additional_points_data.append(additional_point_data)\n",
    "\n",
    "        dynophore3d_dict[superfeature_id] = {}\n",
    "        dynophore3d_dict[superfeature_id][\"id\"] = superfeature_id\n",
    "        dynophore3d_dict[superfeature_id][\"color\"] = superfeature_color\n",
    "        dynophore3d_dict[superfeature_id][\"center\"] = center_data\n",
    "        dynophore3d_dict[superfeature_id][\"points\"] = additional_points_data\n",
    "\n",
    "    return dynophore3d_dict, dynophore3d_xml\n",
    "\n",
    "\n",
    "def pre_process(pml_path, n_drop = 0, include_time = False):\n",
    "    '''Data pre-processing work flow'''\n",
    "    dynophore_dict, _ = pml_to_dict(pml_path, n_drop = n_drop)\n",
    "    data = extract_norm(dynophore_dict)\n",
    "    data = compute.add_distance_mat(data, dynophore_dict, include_time=include_time)\n",
    "    max_frame = max([x[\"frames\"][-1] for x in data.values()])\n",
    "    print(f\"Data pre-processed: {max_frame} in trajectory\")\n",
    "    \n",
    "    return data, dynophore_dict\n",
    "\n",
    "\n",
    "def get_wrap_data(data):\n",
    "    '''\n",
    "    wrap up information for all clusters of all superfeatures for visualization\n",
    "    \n",
    "    output:\n",
    "     [x, y, z, (frame), label in each superfeature, superfeature_nr]\n",
    "    '''\n",
    "    wrap_data = []\n",
    "    for i, key in enumerate(data.keys()):\n",
    "        final_data = data[key][\"non_norm\"]\n",
    "        cluster_temp = data[key][\"clustering\"]\n",
    "        label = cluster_temp._labels.labels\n",
    "        superfeature_nr = np.array([i] * len(final_data))\n",
    "        final_data = np.column_stack((final_data, label))\n",
    "        final_data = np.column_stack((final_data, superfeature_nr))\n",
    "        \n",
    "        wrap_data.append(final_data)\n",
    "    \n",
    "    return wrap_data\n",
    "\n",
    "\n",
    "def get_feature_name(feature):\n",
    "    for i in range(len(feature)):\n",
    "        if feature[i] == '[':\n",
    "            return feature[:i]\n",
    "        \n",
    "\n",
    "def get_env_partner_coord(feature_name, dynophore, pdb_path):\n",
    "    env_partners = list(dynophore.superfeatures[feature_name].__dict__['envpartners'].keys())\n",
    "\n",
    "    atom_ids = []\n",
    "\n",
    "    for partner in env_partners:\n",
    "        for i in range(len(partner)):\n",
    "            if partner[i] == '[':\n",
    "                left = i+1\n",
    "                ids = partner[left:-1].split(',')\n",
    "                for idx in ids:\n",
    "                    atom_ids.append(int(idx))\n",
    "    partner_coords = np.empty(shape=(0, 3))\n",
    "    pdb_array = write.get_atoms_coord(pdb_path)\n",
    "    for idx in atom_ids:\n",
    "        coord = pdb_array[idx]\n",
    "        partner_coords = np.vstack([partner_coords, coord])\n",
    "\n",
    "    x, y, z = np.mean(partner_coords[:, 0]), np.mean(partner_coords[:, 1]), np.mean(partner_coords[:, 2])\n",
    "    return (x, y, z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
